{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e489fdd",
   "metadata": {},
   "source": [
    "# Tensorbard Tutorial\n",
    "## 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d4480d",
   "metadata": {},
   "source": [
    "Tensorboard is an extension of the TensorFlow containing tools for **visualizing** and **tracking** your model's training.\n",
    "\n",
    "Tensorboard runs parallel to your application, serving a local/remote web application that can be displayed on your browser and embedded (from TensorFlow 2.0) in Jupiter notebooks. \n",
    "\n",
    "Even though Tensorboard was made to be incorporated along **TensorFlow** applications, we can also use it on **Pytorch**.\n",
    "\n",
    "This is an in-deep serial of tutorials covering the following topics:\n",
    "\n",
    "- How to begin using Tensorboard\n",
    "- Tracking metrics \n",
    "- Images\n",
    "- Computing graph visualization\n",
    "- Visualizing weights and biases\n",
    "- Matplotlib compatibility \n",
    "- Reading logs\n",
    "- Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd6170",
   "metadata": {},
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4824d456",
   "metadata": {},
   "source": [
    "Tensorboard (TB) is already included when you install the TensorFlow library. As we said before, TB can also be used on Pytorch. However, in this tutorials we use TensorFlow for building deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542e6444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 15:51:33.090505: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-23 15:51:33.090524: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c922e95d",
   "metadata": {},
   "source": [
    "First we load `MNIST` data from `tf.keras.datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6979e537",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "412d876c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b510123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 3)\n",
    "\n",
    "for index, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(x_train[index])\n",
    "    ax.set_title('Label: {}'.format(y_train[index]))\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac0b2e2",
   "metadata": {},
   "source": [
    "We will use a CNN classifier for testing TB. The model definition can be found in `./toy_model.py`. We will also use this model for future tutorials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "161c790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toy_model import create_model\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e9b3530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 15:51:34.859972: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-23 15:51:34.859993: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-23 15:51:34.860005: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (appa): /proc/driver/nvidia/version does not exist\n",
      "2022-05-23 15:51:34.860235: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "n_classes = tf.unique(y_test).y.shape[0]\n",
    "model = create_model(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b559d627",
   "metadata": {},
   "source": [
    "We compile our model using `Adam()` optimizer and `CategoricalCrossEntropy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8dbe7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ce403",
   "metadata": {},
   "source": [
    "The easiest way to use TB is via [**callbacks**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks). Callbacks are objects/functions running together with our model. Generally, they are triggered after an epoch or forward step.   \n",
    "\n",
    "Let's take a look into the [TB callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad5f5ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "tb_cback = TensorBoard(log_dir='logs', update_freq='epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6206b4b8",
   "metadata": {},
   "source": [
    "Before training we need to reshape `x_train` and `y_train` in order to satisfies our network's architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42491db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f43750a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([60000, 28, 28, 1]), TensorShape([60000, 10]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_net = tf.expand_dims(x_train, axis=3)\n",
    "y_train_net = tf.one_hot(y_train, n_classes)\n",
    "\n",
    "x_train_net.shape, y_train_net.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695ad087",
   "metadata": {},
   "source": [
    "A log folder (called `log_dir='logs'`) will be automatically create when we start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4ca2167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.9047 - accuracy: 0.8513 - val_loss: 0.2323 - val_accuracy: 0.9458\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.1650 - accuracy: 0.9595 - val_loss: 0.1546 - val_accuracy: 0.9632\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.0950 - accuracy: 0.9731 - val_loss: 0.1245 - val_accuracy: 0.9674\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 9s 45ms/step - loss: 0.0648 - accuracy: 0.9811 - val_loss: 0.0976 - val_accuracy: 0.9751\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0472 - accuracy: 0.9863 - val_loss: 0.1024 - val_accuracy: 0.9733\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0373 - accuracy: 0.9890 - val_loss: 0.0832 - val_accuracy: 0.9801\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0272 - accuracy: 0.9920 - val_loss: 0.0814 - val_accuracy: 0.9812\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0212 - accuracy: 0.9930 - val_loss: 0.0923 - val_accuracy: 0.9797\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.0787 - val_accuracy: 0.9838\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0784 - val_accuracy: 0.9839\n",
      "CPU times: user 8min 53s, sys: 17.9 s, total: 9min 11s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(x_train_net, \n",
    "                    y_train_net, \n",
    "                    batch_size=256, \n",
    "                    epochs=10, \n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[tb_cback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6494b6ed",
   "metadata": {},
   "source": [
    "open your terminal and type:\n",
    "```\n",
    "tensorboard --logdir <logs directory>\n",
    "```\n",
    "In this case we define `<logs directory>` is `logs`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a141b851",
   "metadata": {},
   "source": [
    "Alternatevely, we can load our tensorboard results on jupyter notebook by loading TB extension,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac505a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258ef7fe",
   "metadata": {},
   "source": [
    "and serving the web app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9c562d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 8370), started 0:01:21 ago. (Use '!kill 8370' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a6d79eeef7fb3123\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a6d79eeef7fb3123\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15677bcd",
   "metadata": {},
   "source": [
    "If you are running TB remotely you also have tu specify the `host` and the opened `port`\n",
    "```\n",
    "tensorboard --logdir logs --host 0.0.0.0 --port 6006\n",
    "```\n",
    "Then, in your browser you can open the link by typing: \n",
    "\n",
    "```\n",
    "http://my_public_ip:6006/\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185e6c95",
   "metadata": {},
   "source": [
    "## [Bonus] Custom training loops (lower level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0888a035",
   "metadata": {},
   "source": [
    "Using TB on Keras-based models is fast and easy to implement. However, sometimes we must use [custom training loops](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) to incorporate more sophisticated features into our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "241df20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from toy_model import train_step, test_step\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb6a8b5",
   "metadata": {},
   "source": [
    "In this case we **can not use the TB callback**. Instead we will use the `tf.summary` package that contains TB tools for tracking runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "eceedbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.summary import create_file_writer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8b94cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './logs_2'\n",
    "train_writer = create_file_writer('{}/train'.format(log_dir))\n",
    "val_writer   = create_file_writer('{}/val'.format(log_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c26ae4",
   "metadata": {},
   "source": [
    "we also have to create our validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "86c78d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ds, x_val_ds, \\\n",
    "y_train_ds, y_val_ds = train_test_split(x_train_net.numpy(), \n",
    "                                        y_train_net.numpy(), \n",
    "                                        test_size=0.2)\n",
    "\n",
    "train_ds  = tf.data.Dataset.from_tensor_slices((x_train_ds, \n",
    "                                                y_train_ds))\n",
    "train_ds  = train_ds.batch(256)\n",
    "\n",
    "val_ds  = tf.data.Dataset.from_tensor_slices((x_val_ds, \n",
    "                                              y_val_ds))\n",
    "val_ds  = val_ds.batch(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78250ba",
   "metadata": {},
   "source": [
    "We reset the optimizer and models weights to avoid overfitting from the last experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "368c8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7d6184ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aa5b41",
   "metadata": {},
   "source": [
    "Finally we start training and saving our logs using `tf.summary.scalar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5b6412f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 40s, sys: 32.5 s, total: 11min 12s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(10):\n",
    "    train_losses, train_accs = [], []\n",
    "    for x, y in train_ds:\n",
    "        t_loss, t_acc = train_step(model, x, y, optimizer)\n",
    "        train_losses.append(t_loss)\n",
    "        train_accs.append(t_acc)\n",
    "        \n",
    "    val_losses, val_accs = [], []\n",
    "    for x, y in val_ds:\n",
    "        v_loss, v_acc = test_step(model, x, y)\n",
    "        val_losses.append(v_loss)\n",
    "        val_accs.append(v_acc)\n",
    "        \n",
    "    # Load to Tensorboard\n",
    "    with train_writer.as_default():\n",
    "        tf.summary.scalar('loss',\n",
    "                          tf.reduce_mean(train_losses), \n",
    "                          step=epoch)\n",
    "        tf.summary.scalar('accuracy',\n",
    "                          tf.reduce_mean(train_accs), \n",
    "                          step=epoch)\n",
    "\n",
    "    # Load to Tensorboard\n",
    "    with val_writer.as_default():\n",
    "        tf.summary.scalar('loss',\n",
    "                          tf.reduce_mean(val_losses), \n",
    "                          step=epoch)\n",
    "        tf.summary.scalar('accuracy',\n",
    "                          tf.reduce_mean(val_accs), \n",
    "                          step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe58cc2",
   "metadata": {},
   "source": [
    "`tf.summary` also includes [another kinds of formats](https://www.tensorflow.org/api_docs/python/tf/summary#functions_2) such as audio, images, graphs...\n",
    "\n",
    "We will see more examples on future tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edeeda0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
